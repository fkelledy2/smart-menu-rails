# L2 Database Query Cache Implementation Plan

## üéØ Executive Summary

Implement a comprehensive L2 (Level 2) database query cache layer to optimize complex database queries, reduce database load, and improve application response times.

**Current Status**: Basic L1 cache (Rails.cache) with QueryCacheService  
**Target**: Advanced L2 cache with intelligent invalidation, query result caching, and multi-level cache hierarchy

---

## üìä Current State Analysis

### ‚úÖ Existing Infrastructure

#### **L1 Cache (Application-Level)**
- `QueryCacheService` - Basic query result caching
- `AdvancedCacheService` - Model-level caching with IdentityCache
- `CacheDependencyService` - Cache dependency tracking
- `QueryCacheable` concern - Controller-level query caching

#### **Cache Configuration**
```ruby
# config/environments/production.rb
config.cache_store = :redis_cache_store, {
  url: ENV['REDIS_URL'],
  namespace: 'smart_menu',
  expires_in: 90.minutes
}
```

#### **Existing Cache Types**
- `:metrics_summary` - 5 minutes TTL
- `:system_metrics` - 1 minute TTL
- `:analytics_dashboard` - 10 minutes TTL
- `:order_analytics` - 15 minutes TTL
- `:revenue_reports` - 1 hour TTL
- `:daily_stats` - 6 hours TTL
- `:monthly_reports` - 24 hours TTL

### ‚ùå Gaps Identified

1. **No L2 Query Result Cache**
   - Complex JOIN queries not cached
   - Aggregate queries (COUNT, SUM, AVG) not cached
   - Subquery results not cached

2. **No Query Fingerprinting**
   - Similar queries with different parameters not optimized
   - No query normalization for cache keys

3. **Limited Cache Warming**
   - No proactive cache population
   - Cold start performance issues

4. **No Multi-Level Cache Hierarchy**
   - Only single-level Redis cache
   - No in-memory L1 cache for hot data

5. **Limited Cache Analytics**
   - No query performance tracking
   - No cache effectiveness metrics

---

## üéØ Implementation Strategy

### **Phase 1: L2 Query Cache Foundation**

#### **Objectives**
- Implement query fingerprinting and normalization
- Create L2 cache service with intelligent caching
- Add query result serialization/deserialization
- Implement cache key generation based on SQL

#### **Tasks**

**1.1 Create L2QueryCacheService**
```ruby
# app/services/l2_query_cache_service.rb
class L2QueryCacheService
  # Cache SQL query results with automatic key generation
  # Supports complex queries with JOINs, aggregations, subqueries
  
  def fetch_query(sql, bindings = [], ttl: 5.minutes)
    cache_key = generate_query_fingerprint(sql, bindings)
    
    Rails.cache.fetch(cache_key, expires_in: ttl) do
      execute_and_serialize_query(sql, bindings)
    end
  end
  
  def generate_query_fingerprint(sql, bindings)
    # Normalize SQL and create unique fingerprint
    normalized_sql = normalize_sql(sql)
    binding_hash = Digest::SHA256.hexdigest(bindings.to_json)
    "l2_query:#{Digest::SHA256.hexdigest(normalized_sql)}:#{binding_hash}"
  end
  
  def normalize_sql(sql)
    # Remove whitespace, lowercase, remove comments
    sql.gsub(/\s+/, ' ').strip.downcase
  end
end
```

**1.2 Add Query Result Serialization**
```ruby
# Support for ActiveRecord::Result serialization
def serialize_query_result(result)
  {
    columns: result.columns,
    rows: result.rows,
    column_types: result.column_types
  }
end

def deserialize_query_result(data)
  ActiveRecord::Result.new(
    data[:columns],
    data[:rows],
    data[:column_types]
  )
end
```

**1.3 Create QueryFingerprint Model**
```ruby
# Track query patterns and cache effectiveness
class QueryFingerprint < ApplicationRecord
  # fingerprint, sql_template, hit_count, miss_count, avg_execution_time
end
```

---

### **Phase 2: Complex Query Caching**

#### **Objectives**
- Cache complex JOIN queries
- Cache aggregate queries (COUNT, SUM, AVG, GROUP BY)
- Cache subquery results
- Implement cache warming for common queries

#### **Tasks**

**2.1 Add Cacheable Scopes to Models**
```ruby
# app/models/concerns/l2_cacheable.rb
module L2Cacheable
  extend ActiveSupport::Concern
  
  class_methods do
    def cached_query(cache_key, ttl: 5.minutes, &block)
      L2QueryCacheService.fetch_query(
        block.call.to_sql,
        [],
        ttl: ttl
      )
    end
    
    def with_l2_cache(ttl: 5.minutes)
      relation = all
      relation.extend(L2CacheableRelation)
      relation.instance_variable_set(:@l2_cache_ttl, ttl)
      relation
    end
  end
end

module L2CacheableRelation
  def load
    ttl = @l2_cache_ttl || 5.minutes
    L2QueryCacheService.fetch_query(to_sql, bind_values, ttl: ttl)
  end
end
```

**2.2 Cache Complex Queries**
```ruby
# Example: Restaurant dashboard with complex aggregations
def restaurant_dashboard_data
  Restaurant.with_l2_cache(ttl: 10.minutes)
    .joins(:menus, :ordrs)
    .select('restaurants.*, 
             COUNT(DISTINCT menus.id) as menu_count,
             COUNT(DISTINCT ordrs.id) as order_count,
             SUM(ordrs.gross) as total_revenue')
    .group('restaurants.id')
    .where(user_id: current_user.id)
end
```

**2.3 Cache Aggregate Queries**
```ruby
# Cache expensive COUNT queries
def total_orders_count
  cache_key = "restaurant:#{id}:orders:count"
  L2QueryCacheService.fetch(cache_key, ttl: 1.hour) do
    ordrs.count
  end
end

# Cache SUM queries
def total_revenue
  cache_key = "restaurant:#{id}:revenue:sum"
  L2QueryCacheService.fetch(cache_key, ttl: 15.minutes) do
    ordrs.sum(:gross)
  end
end
```

---

### **Phase 3: Multi-Level Cache Hierarchy**

#### **Objectives**
- Implement in-memory L1 cache for hot data
- Create cache hierarchy (Memory ‚Üí Redis ‚Üí Database)
- Add cache promotion/demotion logic
- Implement cache statistics and monitoring

#### **Tasks**

**3.1 Create Multi-Level Cache Service**
```ruby
# app/services/multi_level_cache_service.rb
class MultiLevelCacheService
  # L1: In-memory cache (fast, small, per-process)
  # L2: Redis cache (shared, persistent)
  # L3: Database (source of truth)
  
  def fetch(key, l1_ttl: 30.seconds, l2_ttl: 5.minutes, &block)
    # Try L1 (memory)
    result = l1_cache.read(key)
    return result if result
    
    # Try L2 (Redis)
    result = Rails.cache.fetch(key, expires_in: l2_ttl) do
      # L3 (Database)
      block.call
    end
    
    # Promote to L1
    l1_cache.write(key, result, expires_in: l1_ttl)
    result
  end
  
  def l1_cache
    @l1_cache ||= ActiveSupport::Cache::MemoryStore.new(size: 32.megabytes)
  end
end
```

**3.2 Add Cache Promotion Logic**
```ruby
# Promote frequently accessed items to L1
def promote_to_l1(key)
  value = Rails.cache.read(key)
  l1_cache.write(key, value, expires_in: 30.seconds) if value
end

# Track access patterns
def track_cache_access(key)
  access_count = Rails.cache.increment("access_count:#{key}", 1)
  promote_to_l1(key) if access_count > 10
end
```

---

### **Phase 4: Intelligent Cache Invalidation**

#### **Objectives**
- Implement query-based cache invalidation
- Add automatic invalidation on model updates
- Create cache dependency graph
- Implement selective cache clearing

#### **Tasks**

**4.1 Query-Based Invalidation**
```ruby
# app/services/query_invalidation_service.rb
class QueryInvalidationService
  # Invalidate caches based on affected tables
  def invalidate_for_model(model_class)
    table_name = model_class.table_name
    
    # Clear all queries involving this table
    L2QueryCacheService.clear_pattern("*#{table_name}*")
    
    # Clear dependent caches
    invalidate_dependent_caches(model_class)
  end
  
  def invalidate_dependent_caches(model_class)
    dependencies = CacheDependencyService.get_dependencies(model_class)
    dependencies.each do |dep|
      L2QueryCacheService.clear_pattern("*#{dep}*")
    end
  end
end
```

**4.2 Model Callbacks for Cache Invalidation**
```ruby
# app/models/concerns/l2_cache_invalidation.rb
module L2CacheInvalidation
  extend ActiveSupport::Concern
  
  included do
    after_commit :invalidate_l2_caches, on: [:create, :update, :destroy]
  end
  
  def invalidate_l2_caches
    QueryInvalidationService.invalidate_for_model(self.class)
  end
end
```

**4.3 Selective Cache Clearing**
```ruby
# Clear only affected queries
def clear_restaurant_caches(restaurant_id)
  patterns = [
    "restaurant:#{restaurant_id}:*",
    "*restaurants.id = #{restaurant_id}*",
    "*restaurant_id:#{restaurant_id}*"
  ]
  
  patterns.each { |pattern| L2QueryCacheService.clear_pattern(pattern) }
end
```

---

### **Phase 5: Cache Warming & Monitoring**

#### **Objectives**
- Implement proactive cache warming
- Add cache performance monitoring
- Create cache effectiveness dashboard
- Implement cache health checks

#### **Tasks**

**5.1 Cache Warming Job**
```ruby
# app/jobs/l2_cache_warming_job.rb
class L2CacheWarmingJob < ApplicationJob
  queue_as :low_priority
  
  def perform(user_id = nil)
    if user_id
      warm_user_caches(user_id)
    else
      warm_global_caches
    end
  end
  
  def warm_user_caches(user_id)
    user = User.find(user_id)
    
    # Warm restaurant dashboard
    user.restaurants.each do |restaurant|
      restaurant.dashboard_data
      restaurant.order_analytics
      restaurant.revenue_summary
    end
  end
  
  def warm_global_caches
    # Warm frequently accessed queries
    Restaurant.popular_restaurants
    Menu.trending_menus
    Ordr.recent_orders
  end
end
```

**5.2 Cache Performance Monitoring**
```ruby
# app/services/l2_cache_monitor_service.rb
class L2CacheMonitorService
  def collect_metrics
    {
      l1_hit_rate: calculate_l1_hit_rate,
      l2_hit_rate: calculate_l2_hit_rate,
      total_queries: total_query_count,
      cache_size: estimate_cache_size,
      top_queries: top_cached_queries,
      slow_queries: identify_slow_queries,
      cache_effectiveness: calculate_effectiveness
    }
  end
  
  def calculate_effectiveness
    # Compare cached vs uncached query times
    cached_avg = average_cached_query_time
    uncached_avg = average_uncached_query_time
    
    improvement = ((uncached_avg - cached_avg) / uncached_avg * 100).round(2)
    {
      cached_avg_ms: cached_avg,
      uncached_avg_ms: uncached_avg,
      improvement_percent: improvement
    }
  end
end
```

**5.3 Cache Health Checks**
```ruby
# Add to HealthController
def l2_cache_health
  {
    status: 'healthy',
    l1_cache: check_l1_cache,
    l2_cache: check_l2_cache,
    hit_rates: L2CacheMonitorService.hit_rates,
    cache_size: L2CacheMonitorService.cache_size
  }
end
```

---

## üìä Success Metrics

### **Performance Targets**
- ‚úÖ **50% reduction** in database query time for complex queries
- ‚úÖ **80%+ cache hit rate** for frequently accessed queries
- ‚úÖ **<10ms response time** for cached queries
- ‚úÖ **90% reduction** in database load for dashboard queries

### **Cache Effectiveness**
- ‚úÖ **L1 hit rate**: >70% for hot data
- ‚úÖ **L2 hit rate**: >85% for warm data
- ‚úÖ **Cache memory usage**: <100MB per process
- ‚úÖ **Cache invalidation latency**: <100ms

### **Query Optimization**
- ‚úÖ **Complex JOIN queries**: 5x faster with cache
- ‚úÖ **Aggregate queries**: 10x faster with cache
- ‚úÖ **Dashboard queries**: 15x faster with cache

---

## üéØ Implementation Timeline

### **Week 1: Foundation**
- Day 1-2: Create L2QueryCacheService
- Day 3-4: Implement query fingerprinting
- Day 5: Add query result serialization

### **Week 2: Complex Query Caching**
- Day 1-2: Add L2Cacheable concern
- Day 3-4: Cache complex queries in models
- Day 5: Testing and optimization

### **Week 3: Multi-Level Cache**
- Day 1-2: Implement MultiLevelCacheService
- Day 3-4: Add cache promotion logic
- Day 5: Performance testing

### **Week 4: Monitoring & Warming**
- Day 1-2: Implement cache warming
- Day 3-4: Add monitoring and health checks
- Day 5: Documentation and final testing

---

## üîß Usage Examples

### **Basic L2 Caching**
```ruby
# In model
class Restaurant < ApplicationRecord
  include L2Cacheable
  
  def dashboard_data
    self.class.cached_query("restaurant:#{id}:dashboard", ttl: 10.minutes) do
      Restaurant.joins(:menus, :ordrs)
        .select('restaurants.*, COUNT(menus.id) as menu_count')
        .where(id: id)
    end
  end
end
```

### **Controller Usage**
```ruby
# In controller
def dashboard
  @data = cache_query(
    cache_type: :analytics_dashboard,
    key_parts: ["restaurant", params[:id]],
    force_refresh: force_cache_refresh?
  ) do
    @restaurant.dashboard_data
  end
end
```

### **Multi-Level Cache**
```ruby
# Hot data with L1 + L2
def popular_menus
  MultiLevelCacheService.fetch(
    "popular_menus",
    l1_ttl: 30.seconds,
    l2_ttl: 5.minutes
  ) do
    Menu.popular.limit(10)
  end
end
```

---

## üìö Testing Strategy

### **Unit Tests**
- Query fingerprinting accuracy
- Cache key generation
- Serialization/deserialization
- Cache invalidation logic

### **Integration Tests**
- Multi-level cache hierarchy
- Cache warming effectiveness
- Invalidation cascades
- Performance improvements

### **Performance Tests**
- Cache hit rate measurement
- Query time comparison (cached vs uncached)
- Memory usage monitoring
- Concurrent access handling

---

## üöÄ Expected Benefits

### **Performance**
- **50-90% faster** complex query execution
- **80%+ cache hit rate** for common queries
- **Reduced database load** by 60-70%
- **Improved response times** for dashboards

### **Scalability**
- **Handle 10x more concurrent users** with same database
- **Reduced database connection pool pressure**
- **Better resource utilization**

### **Developer Experience**
- **Simple API** for caching complex queries
- **Automatic cache invalidation**
- **Built-in monitoring and debugging**
- **Clear performance metrics**

---

## üéØ Next Steps

1. Create L2QueryCacheService
2. Implement query fingerprinting
3. Add L2Cacheable concern to models
4. Implement multi-level cache hierarchy
5. Add cache warming and monitoring
6. Write comprehensive tests
7. Deploy and monitor effectiveness

**Estimated Total Time**: 4 weeks  
**Priority**: High (Performance Optimization)
